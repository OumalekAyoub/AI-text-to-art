{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxCF3uoDGfOV"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21rCVSDIHOvb",
        "outputId": "65092b27-e024-45b6-c095-05d46358d495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'feed_forward_vqgan_clip'...\n",
            "remote: Enumerating objects: 509, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 509 (delta 0), reused 0 (delta 0), pack-reused 504\u001b[K\n",
            "Receiving objects: 100% (509/509), 1.86 MiB | 16.84 MiB/s, done.\n",
            "Resolving deltas: 100% (299/299), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mehdidc/feed_forward_vqgan_clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlhyrVMwHTMP",
        "outputId": "019227bb-b8cd-4a17-fe47-036c86f94aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feed_forward_vqgan_clip\n"
          ]
        }
      ],
      "source": [
        "cd feed_forward_vqgan_clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zOW5xX-IHW3T",
        "outputId": "8aa89837-3958-4686-8071-474a14467994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Collecting clip-anytorch\n",
            "  Downloading clip_anytorch-2.4.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting clize\n",
            "  Downloading clize-4.2.1-py2.py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 101 kB/s \n",
            "\u001b[?25hCollecting einops==0.3.0\n",
            "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.4.1)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.5-py2.py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.21.6)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (7.1.2)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (2.23.0)\n",
            "Collecting taming-transformers-rom1504\n",
            "  Downloading taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 286 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.8.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.11.0+cu113)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.0-py3-none-any.whl (418 kB)\n",
            "\u001b[K     |████████████████████████████████| 418 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.12.0+cu113)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.12.0)\n",
            "Collecting entmax\n",
            "  Downloading entmax-1.0.tar.gz (7.2 kB)\n",
            "Collecting x-transformers==0.19.1\n",
            "  Downloading x_transformers-0.19.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip-anytorch->-r requirements.txt (line 2)) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip-anytorch->-r requirements.txt (line 2)) (2019.12.20)\n",
            "Collecting sigtools>=2.0\n",
            "  Downloading sigtools-2.0.3-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs<22,>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 3)) (21.4.0)\n",
            "Collecting od\n",
            "  Downloading od-2.0.2-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: docutils~=0.17.0 in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 3)) (0.17.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia->-r requirements.txt (line 8)) (21.3)\n",
            "Collecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.1 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 11)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 11)) (2.8.2)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 13)) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.3.7)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.46.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 14)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 14)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 14)) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 14)) (1.24.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 16)) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 16)) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia->-r requirements.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 16)) (3.2.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 5)) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, entmax\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=cf3d6d3273a292fae6d284284510a30c4a75b3e333491da638665a90b0f9ee4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for entmax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for entmax: filename=entmax-1.0-py3-none-any.whl size=11015 sha256=31cee7a76a778a4f9af9eeed6f9d24a266056b15b0ae080dd6c2d6dae4662626\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/e8/0d/acc29c2f66e69a1f42483347fa8545c293dec12325ee161716\n",
            "Successfully built antlr4-python3-runtime entmax\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, antlr4-python3-runtime, sigtools, pytorch-lightning, omegaconf, od, ftfy, entmax, einops, x-transformers, taming-transformers-rom1504, kornia, clize, clip-anytorch\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 asynctest-0.13.0 clip-anytorch-2.4.0 clize-4.2.1 einops-0.3.0 entmax-1.0 frozenlist-1.3.0 fsspec-2022.5.0 ftfy-6.1.1 kornia-0.6.5 multidict-6.0.2 od-2.0.2 omegaconf-2.2.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 sigtools-2.0.3 taming-transformers-rom1504-0.0.6 torchmetrics-0.9.0 x-transformers-0.19.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JQ6OMW3HmBw"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6NZ3ayZHobu",
        "outputId": "9a76b0f4-fd03-4093-8605-2fa1ad195852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-02 08:58:53--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T085854Z&X-Amz-Expires=300&X-Amz-Signature=f58572685087565cd21c3e79ffb4749f0a09da23cc74f21dd748ddadd19c109c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-06-02 08:58:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T085854Z&X-Amz-Expires=300&X-Amz-Signature=f58572685087565cd21c3e79ffb4749f0a09da23cc74f21dd748ddadd19c109c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67040989 (64M) [application/octet-stream]\n",
            "Saving to: ‘RealESRGAN_x4plus.pth’\n",
            "\n",
            "RealESRGAN_x4plus.p 100%[===================>]  63.93M   222MB/s    in 0.3s    \n",
            "\n",
            "2022-06-02 08:58:54 (222 MB/s) - ‘RealESRGAN_x4plus.pth’ saved [67040989/67040989]\n",
            "\n",
            "--2022-06-02 08:58:54--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/b6ba2c89-c8e5-4fdd-8b79-f906841fcdce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T085854Z&X-Amz-Expires=300&X-Amz-Signature=90c6aaa559e1e32dad0c1bbe94c99b8672e08c71426fe507c111d775ee2a9d64&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x2plus.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-06-02 08:58:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/b6ba2c89-c8e5-4fdd-8b79-f906841fcdce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T085854Z&X-Amz-Expires=300&X-Amz-Signature=90c6aaa559e1e32dad0c1bbe94c99b8672e08c71426fe507c111d775ee2a9d64&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x2plus.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67061725 (64M) [application/octet-stream]\n",
            "Saving to: ‘RealESRGAN_x2plus.pth’\n",
            "\n",
            "RealESRGAN_x2plus.p 100%[===================>]  63.95M  44.1MB/s    in 1.4s    \n",
            "\n",
            "2022-06-02 08:58:56 (44.1 MB/s) - ‘RealESRGAN_x2plus.pth’ saved [67061725/67061725]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Optional, only for super-resolution\n",
        "!wget  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth \n",
        "!wget  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Z4S8_NHr8L",
        "outputId": "3a53d682-2d91-4bbb-94b5-21dad7ca02dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Real-ESRGAN'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 46 (delta 13), reused 33 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n",
            "/content/feed_forward_vqgan_clip/Real-ESRGAN\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.12.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->-r requirements.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.0->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.0->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.0->-r requirements.txt (line 5)) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.0->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.0->-r requirements.txt (line 5)) (1.24.3)\n",
            "/content/feed_forward_vqgan_clip\n"
          ]
        }
      ],
      "source": [
        "# Optional, only for super-resolution\n",
        "!git clone https://github.com/sberbank-ai/Real-ESRGAN\n",
        "%cd Real-ESRGAN\n",
        "!pip install -r requirements.txt\n",
        "%cd ..\n",
        "scale = 4 # either 2 or 4\n",
        "sys.path.append(\"Real-ESRGAN\")\n",
        "from realesrgan import RealESRGAN\n",
        "realesrgan = RealESRGAN(device, scale=scale)\n",
        "realesrgan.load_weights(f'RealESRGAN_x{scale}plus.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUQTuP3mHxYG"
      },
      "outputs": [],
      "source": [
        "#check available models at https://github.com/mehdidc/feed_forward_vqgan_clip/releases\n",
        "from download_weights import model_url, download\n",
        "download(\"https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.1/vqgan_imagenet_f16_16384.yaml\")\n",
        "download(\"https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.1/vqgan_imagenet_f16_16384.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N02J0IK5H0L8"
      },
      "source": [
        "# Start from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3R2JkqH27j"
      },
      "outputs": [],
      "source": [
        "# Model selection\n",
        "\n",
        "def model_selection() :\n",
        "  \n",
        "  import ipywidgets as widgets\n",
        "  dropdown = widgets.Dropdown(\n",
        "      options=model_url.keys(),\n",
        "      value='cc12m_32x1024_mlp_mixer_clip_ViTB32_256x256_v0.3.th',\n",
        "      description='Model:',\n",
        "      disabled=False,\n",
        "      layout={'width': 'max-content'},\n",
        "  )\n",
        "  print(\"Please select the model:\")\n",
        "  return dropdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bi6ctBlH4ew"
      },
      "outputs": [],
      "source": [
        "# Download the selected model\n",
        "def download_model(value,text) :\n",
        "  \n",
        "  model_path = value\n",
        "  if 'cloob' in model_path:\n",
        "    download(\"https://ml.jku.at/research/CLOOB/downloads/checkpoints/cloob_rn50_yfcc_epoch_28.pt\")\n",
        "  print(\"Selected model: \", model_path)\n",
        "  if not os.path.exists(model_path):\n",
        "    print(\"Downloading\", model_path)\n",
        "    url = model_url[model_path]\n",
        "    !wget $url --output-document=$model_path\n",
        "\n",
        "  \n",
        "  from IPython.display import Image\n",
        "  import torch\n",
        "  import clip\n",
        "  from main import load_vqgan_model, CLIP_DIM, clamp_with_grad, synth, load_clip_model\n",
        "  import torchvision\n",
        "  net = torch.load(model_path, map_location=\"cpu\").to(device)\n",
        "  config = net.config\n",
        "  vqgan_config = config.vqgan_config \n",
        "  vqgan_checkpoint = config.vqgan_checkpoint\n",
        "  clip_model = config.clip_model\n",
        "  clip_dim = CLIP_DIM[clip_model]\n",
        "  if config.get(\"clip_model_path\"):\n",
        "    assert os.path.exists(config.clip_model_path)\n",
        "  perceptor = load_clip_model(clip_model, path=config.get(\"clip_model_path\")).eval().requires_grad_(False).to(device)\n",
        "  model = load_vqgan_model(vqgan_config, vqgan_checkpoint).to(device)\n",
        "  z_min = model.quantize.embedding.weight.min(dim=0).values[None, :, None, None]\n",
        "  z_max = model.quantize.embedding.weight.max(dim=0).values[None, :, None, None]\n",
        "\n",
        "  # Please provide a single or a list of text prompts.\n",
        "  # Each text prompt of the list is used to generate an independent image.\n",
        "  texts = [\n",
        "    #\"Picture of a futuristic snowy city during the night, the tree is lit with a lantern.\",\n",
        "    #\"Castle made of chocolate\",\n",
        "    #\"Mushroom with strange colors\", \n",
        "    #\"a professional high quality illustration of a giraffe spider chimera. a giraffe imitating a spider. a giraffe made of spider.\",\n",
        "    #\"bedroom from 1700\",\n",
        "    text,\n",
        "  ]\n",
        "  toks = clip.tokenize(texts, truncate=True)\n",
        "  H = perceptor.encode_text(toks.to(device)).float()\n",
        "  with torch.no_grad():\n",
        "      z = net(H)\n",
        "      z = clamp_with_grad(z, z_min.min(),\n",
        "      z_max.max())\n",
        "      xr = synth(model, z)\n",
        "  grid = torchvision.utils.make_grid(xr.cpu(), nrow=len(xr))\n",
        "  pil_image = torchvision.transforms.functional.to_pil_image(grid)\n",
        "  return pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7Z-amihH6Jv"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path, text) :\n",
        "  \n",
        "  from IPython.display import Image\n",
        "  import torch\n",
        "  import clip\n",
        "  from main import load_vqgan_model, CLIP_DIM, clamp_with_grad, synth, load_clip_model\n",
        "  import torchvision\n",
        "  net = torch.load(model_path, map_location=\"cpu\").to(device)\n",
        "  config = net.config\n",
        "  vqgan_config = config.vqgan_config \n",
        "  vqgan_checkpoint = config.vqgan_checkpoint\n",
        "  clip_model = config.clip_model\n",
        "  clip_dim = CLIP_DIM[clip_model]\n",
        "  if config.get(\"clip_model_path\"):\n",
        "    assert os.path.exists(config.clip_model_path)\n",
        "  perceptor = load_clip_model(clip_model, path=config.get(\"clip_model_path\")).eval().requires_grad_(False).to(device)\n",
        "  model = load_vqgan_model(vqgan_config, vqgan_checkpoint).to(device)\n",
        "  z_min = model.quantize.embedding.weight.min(dim=0).values[None, :, None, None]\n",
        "  z_max = model.quantize.embedding.weight.max(dim=0).values[None, :, None, None]\n",
        "\n",
        "  return generate_image(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTgSNyDsH8Jp"
      },
      "outputs": [],
      "source": [
        "def generate_image(text):\n",
        "  import clip\n",
        "  \n",
        "  # Please provide a single or a list of text prompts.\n",
        "  # Each text prompt of the list is used to generate an independent image.\n",
        "  texts = [\n",
        "    #\"Picture of a futuristic snowy city during the night, the tree is lit with a lantern.\",\n",
        "    #\"Castle made of chocolate\",\n",
        "    #\"Mushroom with strange colors\", \n",
        "    #\"a professional high quality illustration of a giraffe spider chimera. a giraffe imitating a spider. a giraffe made of spider.\",\n",
        "    #\"bedroom from 1700\",\n",
        "    text,\n",
        "  ]\n",
        "  toks = clip.tokenize(texts, truncate=True)\n",
        "  H = perceptor.encode_text(toks.to(device)).float()\n",
        "  with torch.no_grad():\n",
        "      z = net(H)\n",
        "      z = clamp_with_grad(z, z_min.min(),\n",
        "      z_max.max())\n",
        "      xr = synth(model, z)\n",
        "  grid = torchvision.utils.make_grid(xr.cpu(), nrow=len(xr))\n",
        "  pil_image = torchvision.transforms.functional.to_pil_image(grid)\n",
        "  return pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkhwWweaICEX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.mkdir('templates')\n",
        "os.mkdir('static')\n",
        "os.mkdir('static/pics')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrQsfmsbID-_",
        "outputId": "22c11d7d-0443-4228-9efc-b04d6833d04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feed_forward_vqgan_clip/templates\n"
          ]
        }
      ],
      "source": [
        "cd templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n7qRsweIJ9p",
        "outputId": "0394ee70-258f-4668-d5f8-bb66e16f95c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing index.html\n"
          ]
        }
      ],
      "source": [
        "%%writefile index.html\n",
        "\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>NFT Generation with GANs</title>\n",
        "  \n",
        "\n",
        "  <style >\n",
        "    \n",
        "    * {\n",
        "  padding: 0;\n",
        "  margin: 0;\n",
        "  color: #1a1f36;\n",
        "  box-sizing: border-box;\n",
        "  word-wrap: break-word;\n",
        "  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Ubuntu,sans-serif;\n",
        "}\n",
        "body {\n",
        "    min-height: 100%;\n",
        "    background-color: #ffffff;\n",
        "}\n",
        "h1 {\n",
        "    letter-spacing: -1px;\n",
        "}\n",
        "a {\n",
        "  color: #5469d4;\n",
        "  text-decoration: unset;\n",
        "}\n",
        ".login-root {\n",
        "    background: #fff;\n",
        "    display: flex;\n",
        "    width: 100%;\n",
        "    min-height: 100vh;\n",
        "    overflow: hidden;\n",
        "}\n",
        ".loginbackground {\n",
        "    min-height: 692px;\n",
        "    position: fixed;\n",
        "    bottom: 0;\n",
        "    left: 0;\n",
        "    right: 0;\n",
        "    top: 0;\n",
        "    z-index: 0;\n",
        "    overflow: hidden;\n",
        "}\n",
        ".flex-flex {\n",
        "    display: flex;\n",
        "}\n",
        ".align-center {\n",
        "  align-items: center; \n",
        "}\n",
        ".center-center {\n",
        "  align-items: center;\n",
        "  justify-content: center;\n",
        "}\n",
        ".box-root {\n",
        "    box-sizing: border-box;\n",
        "}\n",
        ".flex-direction--column {\n",
        "    -ms-flex-direction: column;\n",
        "    flex-direction: column;\n",
        "}\n",
        ".loginbackground-gridContainer {\n",
        "    display: -ms-grid;\n",
        "    display: grid;\n",
        "    -ms-grid-columns: [start] 1fr [left-gutter] (86.6px)[16] [left-gutter] 1fr [end];\n",
        "    grid-template-columns: [start] 1fr [left-gutter] repeat(16,86.6px) [left-gutter] 1fr [end];\n",
        "    -ms-grid-rows: [top] 1fr [top-gutter] (64px)[8] [bottom-gutter] 1fr [bottom];\n",
        "    grid-template-rows: [top] 1fr [top-gutter] repeat(8,64px) [bottom-gutter] 1fr [bottom];\n",
        "    justify-content: center;\n",
        "    margin: 0 -2%;\n",
        "    transform: rotate(-12deg) skew(-12deg);\n",
        "}\n",
        ".box-divider--light-all-2 {\n",
        "    box-shadow: inset 0 0 0 2px #041c2c;\n",
        "}\n",
        ".box-background--blue {\n",
        "    background-color: #000;\n",
        "}\n",
        ".box-background--white {\n",
        "  background-color: #ffffff; \n",
        "}\n",
        ".box-background--blue800 {\n",
        "    background-color: #212d63;\n",
        "}\n",
        ".box-background--gray100 {\n",
        "    background-color: #e3e8ee;\n",
        "}\n",
        ".box-background--cyan200 {\n",
        "    background-color: #000;\n",
        "}\n",
        ".padding-top--64 {\n",
        "  padding-top: 64px;\n",
        "}\n",
        ".padding-top--24 {\n",
        "  padding-top: 24px;\n",
        "}\n",
        ".padding-top--48 {\n",
        "  padding-top: 48px;\n",
        "}\n",
        ".padding-bottom--24 {\n",
        "  padding-bottom: 24px;\n",
        "}\n",
        ".padding-horizontal--48 {\n",
        "  padding: 48px;\n",
        "}\n",
        ".padding-bottom--15 {\n",
        "  padding-bottom: 15px;\n",
        "}\n",
        "\n",
        "\n",
        ".flex-justifyContent--center {\n",
        "  -ms-flex-pack: center;\n",
        "  justify-content: center;\n",
        "}\n",
        "\n",
        ".formbg {\n",
        "    margin: 0px auto;\n",
        "    width: 100%;\n",
        "    max-width: 448px;\n",
        "    background: white;\n",
        "    border-radius: 4px;\n",
        "    box-shadow: rgba(60, 66, 87, 0.12) 0px 7px 14px 0px, rgba(0, 0, 0, 0.12) 0px 3px 6px 0px;\n",
        "}\n",
        "span {\n",
        "    display: block;\n",
        "    font-size: 20px;\n",
        "    line-height: 28px;\n",
        "    color: #1a1f36;\n",
        "}\n",
        "label {\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        ".reset-pass a,label {\n",
        "    font-size: 14px;\n",
        "    font-weight: 600;\n",
        "    display: block;\n",
        "}\n",
        ".reset-pass > a {\n",
        "    text-align: right;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        ".grid--50-50 {\n",
        "    display: grid;\n",
        "    grid-template-columns: 50% 50%;\n",
        "    align-items: center;\n",
        "}\n",
        "\n",
        ".field input {\n",
        "    font-size: 16px;\n",
        "    line-height: 28px;\n",
        "    padding: 8px 16px;\n",
        "    width: 100%;\n",
        "    min-height: 44px;\n",
        "    border: unset;\n",
        "    border-radius: 4px;\n",
        "    outline-color: rgb(84 105 212 / 0.5);\n",
        "    background-color: rgb(255, 255, 255);\n",
        "    box-shadow: rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(60, 66, 87, 0.16) 0px 0px 0px 1px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px;\n",
        "}\n",
        "\n",
        "input[type=\"submit\"] {\n",
        "    background-color: rgb(84, 105, 212);\n",
        "    box-shadow: rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0.12) 0px 1px 1px 0px, \n",
        "                rgb(84, 105, 212) 0px 0px 0px 1px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(0, 0, 0, 0) 0px 0px 0px 0px, \n",
        "                rgba(60, 66, 87, 0.08) 0px 2px 5px 0px;\n",
        "    color: #fff;\n",
        "    font-weight: 600;\n",
        "    cursor: pointer;\n",
        "}\n",
        ".field-checkbox input {\n",
        "    width: 20px;\n",
        "    height: 15px;\n",
        "    margin-right: 5px; \n",
        "    box-shadow: unset;\n",
        "    min-height: unset;\n",
        "}\n",
        ".field-checkbox label {\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    margin: 0;\n",
        "}\n",
        "a.ssolink {\n",
        "    display: block;\n",
        "    text-align: center;\n",
        "    font-weight: 600;\n",
        "}\n",
        ".footer-link span {\n",
        "    font-size: 14px;\n",
        "    text-align: center;\n",
        "}\n",
        ".listing a {\n",
        "    color: #697386;\n",
        "    font-weight: 600;\n",
        "    margin: 0 10px;\n",
        "}\n",
        "\n",
        ".animationRightLeft {\n",
        "  animation: animationRightLeft 2s ease-in-out infinite;\n",
        "}\n",
        ".animationLeftRight {\n",
        "  animation: animationLeftRight 2s ease-in-out infinite;\n",
        "}\n",
        ".tans3s {\n",
        "  animation: animationLeftRight 3s ease-in-out infinite;\n",
        "}\n",
        ".tans4s {\n",
        "  animation: animationLeftRight 4s ease-in-out infinite;\n",
        "}\n",
        "\n",
        "@keyframes animationLeftRight {\n",
        "  0% {\n",
        "    transform: translateX(0px);\n",
        "  }\n",
        "  50% {\n",
        "    transform: translateX(1000px);\n",
        "  }\n",
        "  100% {\n",
        "    transform: translateX(0px);\n",
        "  }\n",
        "} \n",
        "\n",
        "@keyframes animationRightLeft {\n",
        "  0% {\n",
        "    transform: translateX(0px);\n",
        "  }\n",
        "  50% {\n",
        "    transform: translateX(-1000px);\n",
        "  }\n",
        "  100% {\n",
        "    transform: translateX(0px);\n",
        "  }\n",
        "} \n",
        "  </style>\n",
        "\n",
        "  <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\">\n",
        "\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <div class=\"login-root\">\n",
        "    <div class=\"box-root flex-flex flex-direction--column\" style=\"min-height: 100vh;flex-grow: 1;\">\n",
        "      <div class=\"loginbackground box-background--white padding-top--64\">\n",
        "        <div class=\"loginbackground-gridContainer\">\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: top / start / 8 / end;\">\n",
        "            <div class=\"box-root\" style=\"background-image: linear-gradient(white 0%, rgb(247, 250, 252) 33%); flex-grow: 1;\">\n",
        "            </div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 4 / 2 / auto / 5;\">\n",
        "            <div class=\"box-root box-divider--light-all-2 animationLeftRight tans3s\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 6 / start / auto / 2;\">\n",
        "            <div class=\"box-root box-background--blue800\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 7 / start / auto / 4;\">\n",
        "            <div class=\"box-root box-background--blue animationLeftRight\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 8 / 4 / auto / 6;\">\n",
        "            <div class=\"box-root box-background--gray100 animationLeftRight tans3s\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 2 / 15 / auto / end;\">\n",
        "            <div class=\"box-root box-background--cyan200 animationRightLeft tans4s\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 3 / 14 / auto / end;\">\n",
        "            <div class=\"box-root box-background--blue animationRightLeft\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 4 / 17 / auto / 20;\">\n",
        "            <div class=\"box-root box-background--gray100 animationRightLeft tans4s\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "          <div class=\"box-root flex-flex\" style=\"grid-area: 5 / 14 / auto / 17;\">\n",
        "            <div class=\"box-root box-divider--light-all-2 animationRightLeft tans3s\" style=\"flex-grow: 1;\"></div>\n",
        "          </div>\n",
        "        </div>\n",
        "      </div>\n",
        "      <div class=\"box-root padding-top--24 flex-flex flex-direction--column\" style=\"flex-grow: 1; z-index: 9;\">\n",
        "        <div class=\"box-root padding-top--48 padding-bottom--24 flex-flex flex-justifyContent--center\">\n",
        "          <h1><a href=\"\" style=\"color : #000\" rel=\"dofollow\">DALL-Emades Project</a></h1>\n",
        "        </div>\n",
        "        <div class=\"formbg-outer\">\n",
        "          <div class=\"formbg\">\n",
        "            <div class=\"formbg-inner padding-horizontal--48\">\n",
        "              <span class=\"padding-bottom--15\"></span>\n",
        "\n",
        "\n",
        "    <form action=\"\\generate\" method=\"post\">\n",
        "            <div class=\"form-group\">\n",
        "              <label for=\"text\">Text</label>\n",
        "              <input type=\"text\" class=\"form-control\" name=\"text\" id=\"text\" placeholder=\"Enter text\">\n",
        "            </div>\n",
        "            <div class=\"form-group\">\n",
        "              <label for=\"choix\">Model Selection</label>\n",
        "                  <select class=\"form-control\" name=\"choix\" id=\"choix\" required=\"required\">\n",
        "                    {% for item in list %}       \n",
        "\n",
        "                         <option value=\"{{item}}\">{{item}}</option>\n",
        "\n",
        "                    {% endfor %}\n",
        "                  </select>\n",
        "            </div>\n",
        "            <center>\n",
        "              <button type=\"submit\" class=\"btn btn-primary mb-2\">Generate</button>\n",
        "            </center>\n",
        "    </form>\n",
        "            </div>\n",
        "          </div>\n",
        "          <div class=\"footer-link padding-top--24\">\n",
        "            <div class=\"listing padding-top--24 padding-bottom--24 flex-flex center-center\">\n",
        "              <span><a href=\"#\"></a></span>\n",
        "              <span><a href=\"#\"></a></span>\n",
        "              <span><a href=\"#\"></a></span>\n",
        "            </div>\n",
        "          </div>\n",
        "        </div>\n",
        "      </div>\n",
        "    </div>\n",
        "  </div>\n",
        "</body>\n",
        "\n",
        "</html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXAfUJDUIK0w",
        "outputId": "9ee4d1e9-ef36-4acb-9217-e429ff76d9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing index2.html\n"
          ]
        }
      ],
      "source": [
        "%%writefile index2.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Index</title>\n",
        "</head>\n",
        "<body>\n",
        "    <center>\n",
        "      <h1 style=\"color:#7fd3ed;\">{{ text }}</h1>\n",
        "      <img src=\"{{ user_image }}\" alt=\"User Image\">\n",
        "    </center>    \n",
        "</body>\n",
        "</html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVkvy79MIN03",
        "outputId": "b7a07ec7-e296-4a3a-cc10-68c2485d66b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feed_forward_vqgan_clip\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW3-hUE4IPTZ",
        "outputId": "84d79e78-da93-4c43-af4a-bb6abe3554df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=c6ed8fff45e708e253f019aad98efa7aadd064bdcc5bc0b695a9f165df572f3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4o4ccbSISYs",
        "outputId": "2509b8da-40e4-4234-8bef-2309451468a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 21YX4iADgQlZsJHP6MJYZW2gUfk_27nZM4pTnQAEXw9tcJoC3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cba05e4bd52f4c359d3ad5eac37dae1a",
            "32eafc1d4f344cbd9e6d39e50dd657ef",
            "e0c2c941f8b7495881c3f60dd55cde88",
            "1febe229a28b454b991805519aff122a",
            "2f785de3a6ea4e42888738187c1d2be0",
            "28b0cecf1343464aa3e78f17f22cbc80",
            "cdbfa48f64914ec981689b7024468fa9",
            "71543d13cd7943d2834f29ad87f41e90",
            "b930820a10b64aa3ba8e3786cce95b24",
            "96c0d69ec23c47ea93212541c592fa4e",
            "78b1e28767924c46b88761cd292ac96c"
          ]
        },
        "id": "NKoV41_lITvx",
        "outputId": "ea7db002-1160-4a6f-a6c1-06fc9916db08"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select the model:\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://065e-35-231-250-244.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:00:32] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [02/Jun/2022 09:00:39] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Downloading cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "--2022-06-02 09:00:48--  https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.1/cc12m_32x1024.th\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/386744753/9bc6ac29-4a75-440d-be35-50eb48367f6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T090048Z&X-Amz-Expires=300&X-Amz-Signature=db9986d99aa2fd9d2a6fdc49c65b39bbc059b9f6c837a9efcc6e2b84f0d6aee4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=386744753&response-content-disposition=attachment%3B%20filename%3Dcc12m_32x1024.th&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-06-02 09:00:48--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/386744753/9bc6ac29-4a75-440d-be35-50eb48367f6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T090048Z&X-Amz-Expires=300&X-Amz-Signature=db9986d99aa2fd9d2a6fdc49c65b39bbc059b9f6c837a9efcc6e2b84f0d6aee4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=386744753&response-content-disposition=attachment%3B%20filename%3Dcc12m_32x1024.th&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1660543745 (1.5G) [application/octet-stream]\n",
            "Saving to: ‘cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th’\n",
            "\n",
            "cc12m_32x1024_vitga 100%[===================>]   1.55G  72.3MB/s    in 20s     \n",
            "\n",
            "2022-06-02 09:01:09 (78.1 MB/s) - ‘cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th’ saved [1660543745/1660543745]\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 354M/354M [00:04<00:00, 71.9MiB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba05e4bd52f4c359d3ad5eac37dae1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to taming/modules/autoencoder/lpips/vgg.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8.19kB [00:00, 497kB/s]                    \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:01:30] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [02/Jun/2022 09:01:31] \"\u001b[37mGET /static/pics/Birds%20in%20a%20forestcc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Downloading cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "--2022-06-02 09:01:56--  https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.2/cc12m_32x1024_vitgan.th\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/386744753/571719da-f6a9-47a3-a8d5-c9bb06571850?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T090156Z&X-Amz-Expires=300&X-Amz-Signature=fca314c790c74449588d3c59d11787ee7c8042cc02cdcc9bdfe2068d94a57c8d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=386744753&response-content-disposition=attachment%3B%20filename%3Dcc12m_32x1024_vitgan.th&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-06-02 09:01:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/386744753/571719da-f6a9-47a3-a8d5-c9bb06571850?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220602T090156Z&X-Amz-Expires=300&X-Amz-Signature=fca314c790c74449588d3c59d11787ee7c8042cc02cdcc9bdfe2068d94a57c8d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=386744753&response-content-disposition=attachment%3B%20filename%3Dcc12m_32x1024_vitgan.th&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1660543121 (1.5G) [application/octet-stream]\n",
            "Saving to: ‘cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th’\n",
            "\n",
            "cc12m_32x1024_vitga 100%[===================>]   1.55G  7.48MB/s    in 1m 51s  \n",
            "\n",
            "2022-06-02 09:03:48 (14.3 MB/s) - ‘cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th’ saved [1660543121/1660543121]\n",
            "\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:03:55] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:03:56] \"\u001b[37mGET /static/pics/Birds%20in%20a%20forestcc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:28:06] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:28:12] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:28:12] \"\u001b[37mGET /static/pics/le%20sport%20est%20la%20santecc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:33:32] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:33:32] \"\u001b[37mGET /static/pics/on%20ne%20peut%20etre%20et%20avoir%20ét%20êcc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:34:25] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:36:27] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:36:28] \"\u001b[37mGET /static/pics/Les%20enfants%20jouent%20cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:37:08] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:37:08] \"\u001b[37mGET /static/pics/Le%20papillon%20vole%20cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:38:05] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 09:38:05] \"\u001b[37mGET /static/pics/la%20voiture%20roule%20dans%20le%20rond%20point%20cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.2.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:01:15] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n",
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:01:49] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:01:49] \"\u001b[37mGET /static/pics/je%20mange%20des%20fritescc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:03:06] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:03:06] \"\u001b[37mGET /static/pics/to%20be%20or%20not%20to%20becc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:03:30] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:03:30] \"\u001b[37mGET /static/pics/je%20monte%20au%20cielcc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:03:57] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:03:58] \"\u001b[37mGET /static/pics/je%20monte%20le%20cielcc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Selected model:  cc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:04:21] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [02/Jun/2022 10:04:23] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [02/Jun/2022 10:04:23] \"\u001b[37mGET /static/pics/je%20montecc12m_32x1024_vitgan_clip_ViTB32_256x256_v0.1.th.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "list_values = model_selection()\n",
        "list = list_values.options\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "  return render_template(\"index.html\",list=list)\n",
        "\n",
        "@app.route('/generate', methods = ['GET', \"POST\"])\n",
        "def generate():\n",
        "  if request.method==\"POST\":\n",
        "    image = download_model(request.form[\"choix\"],request.form[\"text\"])\n",
        "    image = image.save(\"static/pics/\"+request.form[\"text\"]+\"\"+request.form[\"choix\"]+\".jpg\")\n",
        "\n",
        "    PEOPLE_FOLDER = os.path.join('static', 'pics')\n",
        "    app.config['UPLOAD_FOLDER'] = PEOPLE_FOLDER\n",
        "\n",
        "    full_filename = os.path.join(app.config['UPLOAD_FOLDER'], request.form[\"text\"]+\"\"+request.form[\"choix\"]+'.jpg')\n",
        "    return render_template(\"index2.html\", text= request.form[\"text\"], user_image = full_filename)\n",
        "  else :\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DALLEmades.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cba05e4bd52f4c359d3ad5eac37dae1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32eafc1d4f344cbd9e6d39e50dd657ef",
              "IPY_MODEL_e0c2c941f8b7495881c3f60dd55cde88",
              "IPY_MODEL_1febe229a28b454b991805519aff122a"
            ],
            "layout": "IPY_MODEL_2f785de3a6ea4e42888738187c1d2be0"
          }
        },
        "32eafc1d4f344cbd9e6d39e50dd657ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28b0cecf1343464aa3e78f17f22cbc80",
            "placeholder": "​",
            "style": "IPY_MODEL_cdbfa48f64914ec981689b7024468fa9",
            "value": "100%"
          }
        },
        "e0c2c941f8b7495881c3f60dd55cde88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71543d13cd7943d2834f29ad87f41e90",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b930820a10b64aa3ba8e3786cce95b24",
            "value": 553433881
          }
        },
        "1febe229a28b454b991805519aff122a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c0d69ec23c47ea93212541c592fa4e",
            "placeholder": "​",
            "style": "IPY_MODEL_78b1e28767924c46b88761cd292ac96c",
            "value": " 528M/528M [00:04&lt;00:00, 145MB/s]"
          }
        },
        "2f785de3a6ea4e42888738187c1d2be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b0cecf1343464aa3e78f17f22cbc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdbfa48f64914ec981689b7024468fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71543d13cd7943d2834f29ad87f41e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b930820a10b64aa3ba8e3786cce95b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96c0d69ec23c47ea93212541c592fa4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b1e28767924c46b88761cd292ac96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}